{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.1 (from langchain_community)\n",
      "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain_community)\n",
      "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain_community)\n",
      "  Downloading sqlalchemy-2.0.44-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain_community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.13.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain_community)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langsmith<1.0.0,>=0.1.125 (from langchain_community)\n",
      "  Downloading langsmith-0.4.49-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.7.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading propcache-0.4.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading yarl-1.22.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain_community)\n",
      "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.10.3)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.1->langchain_community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.27.0)\n",
      "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.1.125->langchain_community)\n",
      "  Downloading orjson-3.11.4-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.1.125->langchain_community)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain_community)\n",
      "  Downloading zstandard-0.25.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain_community)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain_community)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2024.12.14)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.27.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.2.0)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.13.2-cp310-cp310-macosx_11_0_arm64.whl (489 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
      "Downloading langsmith-0.4.49-py3-none-any.whl (410 kB)\n",
      "Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-macosx_11_0_arm64.whl (49 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-macosx_11_0_arm64.whl (44 kB)\n",
      "Downloading orjson-3.11.4-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (243 kB)\n",
      "Downloading propcache-0.4.1-cp310-cp310-macosx_11_0_arm64.whl (47 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-macosx_11_0_arm64.whl (94 kB)\n",
      "Downloading zstandard-0.25.0-cp310-cp310-macosx_11_0_arm64.whl (640 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.6/640.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, SQLAlchemy, requests, python-dotenv, propcache, orjson, mypy-extensions, multidict, marshmallow, jsonpointer, httpx-sse, frozenlist, async-timeout, aiohappyeyeballs, yarl, typing-inspect, requests-toolbelt, jsonpatch, aiosignal, pydantic-settings, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-classic, langchain_community\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.17.0 requires keras>=3.2.0, but you have keras 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed SQLAlchemy-2.0.44 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 async-timeout-4.0.3 dataclasses-json-0.6.7 frozenlist-1.8.0 httpx-sse-0.4.3 jsonpatch-1.33 jsonpointer-3.0.0 langchain-classic-1.0.0 langchain-core-1.1.0 langchain-text-splitters-1.0.0 langchain_community-0.4.1 langsmith-0.4.49 marshmallow-3.26.1 multidict-6.7.0 mypy-extensions-1.1.0 orjson-3.11.4 propcache-0.4.1 pydantic-settings-2.12.0 python-dotenv-1.2.1 requests-2.32.5 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspect-0.9.0 typing-inspection-0.4.2 yarl-1.22.0 zstandard-0.25.0\n",
      "Collecting openai\n",
      "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai) (4.6.2)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp310-cp310-macosx_11_0_arm64.whl (319 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.12.0 openai-2.8.1\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-openai) (1.1.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-openai) (2.8.1)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (0.4.49)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (2.10.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-openai) (2.27.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.3.0)\n",
      "Downloading langchain_openai-1.1.0-py3-none-any.whl (84 kB)\n",
      "Downloading tiktoken-0.12.0-cp310-cp310-macosx_11_0_arm64.whl (995 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m995.8/995.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-1.1.0 tiktoken-0.12.0\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_community\n",
    "! pip install openai\n",
    "! pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model = \"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>genre</th>\n",
       "      <th>age</th>\n",
       "      <th>comment</th>\n",
       "      <th>kind_of_comment</th>\n",
       "      <th>complaint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alumno</td>\n",
       "      <td>hombre</td>\n",
       "      <td>29</td>\n",
       "      <td>El precio de la comida está carísimo para lo q...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>precio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trabajador</td>\n",
       "      <td>hombre</td>\n",
       "      <td>48</td>\n",
       "      <td>Todo bien, gracias por mantener la cafetería o...</td>\n",
       "      <td>neutro</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>madre</td>\n",
       "      <td>mujer</td>\n",
       "      <td>69</td>\n",
       "      <td>Como madre de familia, el sabor de la comida d...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>sabor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alumno</td>\n",
       "      <td>mujer</td>\n",
       "      <td>20</td>\n",
       "      <td>Me encanta la vibra de la cafetería; siempre h...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alumno</td>\n",
       "      <td>hombre</td>\n",
       "      <td>25</td>\n",
       "      <td>El precio está caro para lo que ofrecen y la a...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>precio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         role   genre  age                                            comment  \\\n",
       "0      alumno  hombre   29  El precio de la comida está carísimo para lo q...   \n",
       "1  trabajador  hombre   48  Todo bien, gracias por mantener la cafetería o...   \n",
       "2       madre   mujer   69  Como madre de familia, el sabor de la comida d...   \n",
       "3      alumno   mujer   20  Me encanta la vibra de la cafetería; siempre h...   \n",
       "4      alumno  hombre   25  El precio está caro para lo que ofrecen y la a...   \n",
       "\n",
       "  kind_of_comment complaint  \n",
       "0        negativo    precio  \n",
       "1          neutro       NaN  \n",
       "2        negativo     sabor  \n",
       "3        positivo       NaN  \n",
       "4        negativo    precio  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/arantxavalenciareyes/Documents/GitHub/proyecto-nlp/respuestas_cafeteria.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Eres un modelo que detecta el tipo de queja de un review\n",
    "Recibes un review y detectas el tipo de queja \n",
    "SOLAMENTE CONTESTA CON EL TIPO DE QUEJA EN MAYUSCULAS EN ESPAÑOL\n",
    "No regreses nada mas\n",
    "\n",
    "Por ejemplo:\n",
    "Review: La cafetería tiene la peor comida del mundo \n",
    "Devuelve: Por comida\n",
    "\n",
    "Review: La cafetería tiene los peores precios\n",
    "Devuelve: Por precio\n",
    "\n",
    "Review: Los meseros son terribles\n",
    "Devuelve: Por calidad\n",
    "\n",
    "Puede recibir reviews en muchos idiomas, pero tu etiqueta final\n",
    "de sentimientos DEBE SIEMPRE de estar en español\n",
    "\"\"\"\n",
    "\n",
    "#Zero-shot learning/prompting -- no ejemplos\n",
    "#Few-shot learning/prompting -- poquitos ejemplos\n",
    "def etiquetar(texto):\n",
    "  result = chat.invoke([\n",
    "    SystemMessage(content=prompt),\n",
    "    HumanMessage(content=texto)\n",
    "  ])\n",
    "  return result.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [13:24<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"etiqueta\"] = df[\"comment\"].progress_apply(etiquetar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>genre</th>\n",
       "      <th>age</th>\n",
       "      <th>comment</th>\n",
       "      <th>kind_of_comment</th>\n",
       "      <th>complaint</th>\n",
       "      <th>etiqueta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alumno</td>\n",
       "      <td>hombre</td>\n",
       "      <td>29</td>\n",
       "      <td>El precio de la comida está carísimo para lo q...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>precio</td>\n",
       "      <td>POR PRECIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trabajador</td>\n",
       "      <td>hombre</td>\n",
       "      <td>48</td>\n",
       "      <td>Todo bien, gracias por mantener la cafetería o...</td>\n",
       "      <td>neutro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NINGUNA QUEJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>madre</td>\n",
       "      <td>mujer</td>\n",
       "      <td>69</td>\n",
       "      <td>Como madre de familia, el sabor de la comida d...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>sabor</td>\n",
       "      <td>POR COMIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alumno</td>\n",
       "      <td>mujer</td>\n",
       "      <td>20</td>\n",
       "      <td>Me encanta la vibra de la cafetería; siempre h...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIN QUEJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alumno</td>\n",
       "      <td>hombre</td>\n",
       "      <td>25</td>\n",
       "      <td>El precio está caro para lo que ofrecen y la a...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>precio</td>\n",
       "      <td>POR PRECIO Y CALIDAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         role   genre  age                                            comment  \\\n",
       "0      alumno  hombre   29  El precio de la comida está carísimo para lo q...   \n",
       "1  trabajador  hombre   48  Todo bien, gracias por mantener la cafetería o...   \n",
       "2       madre   mujer   69  Como madre de familia, el sabor de la comida d...   \n",
       "3      alumno   mujer   20  Me encanta la vibra de la cafetería; siempre h...   \n",
       "4      alumno  hombre   25  El precio está caro para lo que ofrecen y la a...   \n",
       "\n",
       "  kind_of_comment complaint              etiqueta  \n",
       "0        negativo    precio            POR PRECIO  \n",
       "1          neutro       NaN         NINGUNA QUEJA  \n",
       "2        negativo     sabor            POR COMIDA  \n",
       "3        positivo       NaN             SIN QUEJA  \n",
       "4        negativo    precio  POR PRECIO Y CALIDAD  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POR PRECIO', 'NINGUNA QUEJA', 'POR COMIDA', 'SIN QUEJA',\n",
       "       'POR PRECIO Y CALIDAD', 'POR VARIEDAD', 'NINGUNA QUEJA DETECTADA',\n",
       "       'NINGUNA', 'POR INSTALACIONES', 'Por calidad',\n",
       "       'POR PRECIO Y POR CALIDAD', 'POR COMIDA Y POR PRECIO',\n",
       "       'NO HAY QUEJA', 'POR COMIDA Y CALIDAD', 'POR EXPERIENCIA',\n",
       "       'POR NINGUNA', 'POR VARIEDAD DE OPCIONES', 'POR CALIDAD',\n",
       "       'NINGUNA QUEJA DE ESPECIAL RELEVANCIA',\n",
       "       'POR COMIDA Y POR AMBIENTE', 'Sin queja', 'NINGUNAQUEJA',\n",
       "       'POR PRECIO Y COMIDA', 'POR COMIDA Y POR CALIDAD',\n",
       "       'Por atención y ambiente', 'NEUTRO', 'POSITIVO', 'NO ES UNA QUEJA',\n",
       "       'POR VARIEDAD DEL MENÚ Y DISPONIBILIDAD HORARIA',\n",
       "       'POR COMIDA, POR PRECIO, POR CALIDAD', 'POR PRECIO Y POR COMIDA',\n",
       "       'POR COMIDA Y PRECIO', 'SIN QUEJA DETECTADA',\n",
       "       'POR VARIEDAD Y ATENCIÓN', 'POR LIMPIEZA Y MANTENIMIENTO',\n",
       "       'Ninguna queja', 'POR INSTALACIONES Y LIMPIEZA',\n",
       "       'POR VARIEDAD DE OPCIONES Y CALIDAD DE SERVICIO',\n",
       "       'POR FUNCIONAMIENTO', 'POR COMIDA, CALIDAD Y PRECIO',\n",
       "       'POR VARIEDAD, POR CALIDAD, POR COMIDA', 'Por calidad y comida',\n",
       "       'POR COMIDA Y ATENCIÓN', 'POR COMIDA Y SERVICIO', 'NEUTRALIDAD',\n",
       "       'Por condiciones laborales', 'POR PRECIO Y PORCIÓN',\n",
       "       'POR VARIEDAD DEL MENÚ', 'POR VARIEDAD Y PRECIO',\n",
       "       'POR INSTALACIONES Y CALIDAD', 'POR NINGUNA QUEJA',\n",
       "       'POR CALIDAD Y AMBIENTE', 'POR INSTALACIONES Y AMBIENTE',\n",
       "       'POR COMIDA Y CALIDAD Y LIMPIEZA', 'POR ATENCIÓN',\n",
       "       'POR INSTALACIONES Y ATENCIÓN', 'No hay queja', 'No hay queja.',\n",
       "       'POR OPCIONES DE COMIDA', 'Por misceláneo',\n",
       "       'Por experiencia general', 'Por ambiente',\n",
       "       'INSATISFACCIÓN GENERAL', 'SIN QUEJA\\n',\n",
       "       'POR EXPERIENCIA GENERAL NEGATIVA', 'NO QUEJA',\n",
       "       'POR PRECIO Y AMBIENTE', 'POR AMBIENTE E INSTALACIONES',\n",
       "       'NINGUNA QUEJA PRESENTE', 'POR SERVICIO Y VARIEDAD',\n",
       "       'POR SERVICIO', 'POR OPCIONES'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"etiqueta\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def simplificar(text):\n",
    "    if pd.isna(text):\n",
    "        return \"NINGUNA\"\n",
    "\n",
    "    # Normalizar mayúsculas\n",
    "    t = text.upper().strip()\n",
    "\n",
    "    # Quitar puntos, comas dobles, espacios repetidos\n",
    "    t = re.sub(r'[^A-ZÁÉÍÓÚÜÑ ]', ' ', t)\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "\n",
    "    # Lista de patrones que representan \"NINGUNA\"\n",
    "    patrones_ninguna = [\n",
    "        r\"NINGUNA\",\n",
    "        r\"POR NINGUNA\",\n",
    "        r\"NINGUNA QUEJA\",\n",
    "        r\"NINGUNA QUEJA DETECTADA\",\n",
    "        r\"NINGUNA QUEJA DE ESPECIAL RELEVANCIA\",\n",
    "        r\"NO HAY QUEJA\",\n",
    "        r\"POR NINGUNA QUEJA\",\n",
    "        r\"SIN QUEJA\",\n",
    "        r\"SIN QUEJA DETECTADA\",\n",
    "        r\"SIN QUEJA REGISTRADA\",\n",
    "        r\"SIN QUEJA DESTACADA\",\n",
    "        r\"SIN QUEJA DETECTABLE\",\n",
    "        r\"NO ES UNA QUEJA\",\n",
    "        r\"NI UNA QUEJA DETECTADA\",\n",
    "        r\"'NINGUNA QUEJA PRESENTE\",\n",
    "        r\"NINGUNAQUEJA\",\n",
    "        r\"NO QUEJA\",\n",
    "        r\"POR NO HAY QUEJA\",\n",
    "        r\"SATISFACCIÓN SIN QUEJA\",\n",
    "        r\"NO HAY QUEJA\",\n",
    "        r\"POSITIVO\",\n",
    "        r\"NEUTRO\",\n",
    "        r\"NEUTRAL\",\n",
    "        r\"REGULAR\",\n",
    "        r\"SATISFACCIÓN\",\n",
    "    ]\n",
    "\n",
    "    # Si coincide con cualquier patrón → convertir en \"NINGUNA\"\n",
    "    for patt in patrones_ninguna:\n",
    "        if re.fullmatch(patt, t):\n",
    "            return \"NINGUNA\"\n",
    "\n",
    "    # Si no es categoría de \"no queja\" devolver versión limpia\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [00:00<00:00, 52988.90it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"etiqueta\"] = df[\"etiqueta\"].progress_apply(simplificar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POR PRECIO', 'NINGUNA', 'POR COMIDA', 'POR PRECIO Y CALIDAD',\n",
       "       'POR VARIEDAD', 'POR INSTALACIONES', 'POR CALIDAD',\n",
       "       'POR PRECIO Y POR CALIDAD', 'POR COMIDA Y POR PRECIO',\n",
       "       'POR COMIDA Y CALIDAD', 'POR EXPERIENCIA',\n",
       "       'POR VARIEDAD DE OPCIONES', 'POR COMIDA Y POR AMBIENTE',\n",
       "       'POR PRECIO Y COMIDA', 'POR COMIDA Y POR CALIDAD',\n",
       "       'POR ATENCIÓN Y AMBIENTE',\n",
       "       'POR VARIEDAD DEL MENÚ Y DISPONIBILIDAD HORARIA',\n",
       "       'POR COMIDA POR PRECIO POR CALIDAD', 'POR PRECIO Y POR COMIDA',\n",
       "       'POR COMIDA Y PRECIO', 'POR VARIEDAD Y ATENCIÓN',\n",
       "       'POR LIMPIEZA Y MANTENIMIENTO', 'POR INSTALACIONES Y LIMPIEZA',\n",
       "       'POR VARIEDAD DE OPCIONES Y CALIDAD DE SERVICIO',\n",
       "       'POR FUNCIONAMIENTO', 'POR COMIDA CALIDAD Y PRECIO',\n",
       "       'POR VARIEDAD POR CALIDAD POR COMIDA', 'POR CALIDAD Y COMIDA',\n",
       "       'POR COMIDA Y ATENCIÓN', 'POR COMIDA Y SERVICIO', 'NEUTRALIDAD',\n",
       "       'POR CONDICIONES LABORALES', 'POR PRECIO Y PORCIÓN',\n",
       "       'POR VARIEDAD DEL MENÚ', 'POR VARIEDAD Y PRECIO',\n",
       "       'POR INSTALACIONES Y CALIDAD', 'POR CALIDAD Y AMBIENTE',\n",
       "       'POR INSTALACIONES Y AMBIENTE', 'POR COMIDA Y CALIDAD Y LIMPIEZA',\n",
       "       'POR ATENCIÓN', 'POR INSTALACIONES Y ATENCIÓN',\n",
       "       'POR OPCIONES DE COMIDA', 'POR MISCELÁNEO',\n",
       "       'POR EXPERIENCIA GENERAL', 'POR AMBIENTE',\n",
       "       'INSATISFACCIÓN GENERAL', 'POR EXPERIENCIA GENERAL NEGATIVA',\n",
       "       'POR PRECIO Y AMBIENTE', 'POR AMBIENTE E INSTALACIONES',\n",
       "       'NINGUNA QUEJA PRESENTE', 'POR SERVICIO Y VARIEDAD',\n",
       "       'POR SERVICIO', 'POR OPCIONES'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"etiqueta\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {\n",
    "    'POR PRECIO': 0,\n",
    "    'NINGUNA': 1,\n",
    "    'POR COMIDA': 2,\n",
    "    'POR PRECIO Y CALIDAD': 3,\n",
    "    'POR VARIEDAD': 4,\n",
    "    'POR INSTALACIONES':5,\n",
    "    'POR CALIDAD':6,\n",
    "    'POR PRECIO Y POR CALIDAD':7,\n",
    "    'POR COMIDA Y POR PRECIO':8,\n",
    "    'POR COMIDA Y CALIDAD':9,\n",
    "    'POR EXPERIENCIA':10,\n",
    "    'POR VARIEDAD DE OPCIONES':11,\n",
    "    'POR COMIDA Y POR AMBIENTE':12,\n",
    "    'POR PRECIO Y COMIDA':13,\n",
    "    'POR COMIDA Y POR CALIDAD':14,\n",
    "    'POR ATENCIÓN Y AMBIENTE':15,\n",
    "    'POR VARIEDAD DEL MENÚ Y DISPONIBILIDAD HORARIA':16,\n",
    "\n",
    "}\n",
    "df['category'] = df['category'].map(mapper)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -m\n"
     ]
    }
   ],
   "source": [
    "! pip install -m spacy download es_core_news_md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/arantxavalenciareyes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/arantxavalenciareyes/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "100%|██████████| 991/991 [00:04<00:00, 236.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>genre</th>\n",
       "      <th>age</th>\n",
       "      <th>comment</th>\n",
       "      <th>kind_of_comment</th>\n",
       "      <th>complaint</th>\n",
       "      <th>etiqueta</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alumno</td>\n",
       "      <td>hombre</td>\n",
       "      <td>29</td>\n",
       "      <td>El precio de la comida está carísimo para lo q...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>precio</td>\n",
       "      <td>POR PRECIO</td>\n",
       "      <td>[-0.14875248, 2.44785, -1.1195225, 1.2586325, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trabajador</td>\n",
       "      <td>hombre</td>\n",
       "      <td>48</td>\n",
       "      <td>Todo bien, gracias por mantener la cafetería o...</td>\n",
       "      <td>neutro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NINGUNA</td>\n",
       "      <td>[0.15680596, 0.423218, 0.36181802, 0.18416801,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>madre</td>\n",
       "      <td>mujer</td>\n",
       "      <td>69</td>\n",
       "      <td>Como madre de familia, el sabor de la comida d...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>sabor</td>\n",
       "      <td>POR COMIDA</td>\n",
       "      <td>[-0.181757, 1.1510206, -0.35793504, -0.1755714...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alumno</td>\n",
       "      <td>mujer</td>\n",
       "      <td>20</td>\n",
       "      <td>Me encanta la vibra de la cafetería; siempre h...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NINGUNA</td>\n",
       "      <td>[-0.054130316, -0.1566243, -0.050648537, 0.783...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alumno</td>\n",
       "      <td>hombre</td>\n",
       "      <td>25</td>\n",
       "      <td>El precio está caro para lo que ofrecen y la a...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>precio</td>\n",
       "      <td>POR PRECIO Y CALIDAD</td>\n",
       "      <td>[-0.22298999, 2.124965, -0.8448151, 0.10090916...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         role   genre  age                                            comment  \\\n",
       "0      alumno  hombre   29  El precio de la comida está carísimo para lo q...   \n",
       "1  trabajador  hombre   48  Todo bien, gracias por mantener la cafetería o...   \n",
       "2       madre   mujer   69  Como madre de familia, el sabor de la comida d...   \n",
       "3      alumno   mujer   20  Me encanta la vibra de la cafetería; siempre h...   \n",
       "4      alumno  hombre   25  El precio está caro para lo que ofrecen y la a...   \n",
       "\n",
       "  kind_of_comment complaint              etiqueta  \\\n",
       "0        negativo    precio            POR PRECIO   \n",
       "1          neutro       NaN               NINGUNA   \n",
       "2        negativo     sabor            POR COMIDA   \n",
       "3        positivo       NaN               NINGUNA   \n",
       "4        negativo    precio  POR PRECIO Y CALIDAD   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.14875248, 2.44785, -1.1195225, 1.2586325, ...  \n",
       "1  [0.15680596, 0.423218, 0.36181802, 0.18416801,...  \n",
       "2  [-0.181757, 1.1510206, -0.35793504, -0.1755714...  \n",
       "3  [-0.054130316, -0.1566243, -0.050648537, 0.783...  \n",
       "4  [-0.22298999, 2.124965, -0.8448151, 0.10090916...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "tqdm.pandas()\n",
    "\n",
    "stopwords_es = stopwords.words('spanish')\n",
    "no_stopwords = ['como', 'nada', 'ni', 'no', 'poco', 'sin', 'todo']\n",
    "for word in no_stopwords:\n",
    "  if word in stopwords_es:\n",
    "      stopwords_es.remove(word)\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "def vectorize(text):\n",
    "  vector_size = 300\n",
    "  text = text.lower()\n",
    "  text = re.sub(r'[^a-z0-9áéíóúüñ \\t]', ' ', text)\n",
    "  doc = nlp(text)\n",
    "  tokens = [t for t in doc if not t.is_stop and not t.is_punct]\n",
    "  lemmas = [t.lemma_ for t in tokens]\n",
    "  clean_text = \" \".join(lemmas)\n",
    "  vector = nlp(clean_text).vector\n",
    "  return vector\n",
    "\n",
    "\n",
    "# Aplicamos la fórmula de pre-procesamiento\n",
    "df['vector'] = df['comment'].progress_apply(vectorize)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = np.vstack(df['vector'].values)\n",
    "y = df['comment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.80, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 2.9.0\n",
      "Uninstalling keras-2.9.0:\n",
      "  Successfully uninstalled keras-2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "!pip uninstall keras -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorflow) (2.17.0)\n",
      "Collecting keras>=3.2.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from h5py>=3.10.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.0)\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "Successfully installed keras-3.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.16\n",
      "Name: tensorflow\n",
      "Version: 2.17.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, ml-dtypes, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!pip show tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/anaconda3/envs/arantxa/bin/python'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==3.3.3\n",
      "  Downloading keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from keras==3.3.3) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from keras==3.3.3) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from keras==3.3.3) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from keras==3.3.3) (0.0.7)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from keras==3.3.3) (3.12.1)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from keras==3.3.3) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from keras==3.3.3) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from optree->keras==3.3.3) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from rich->keras==3.3.3) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from rich->keras==3.3.3) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/arantxa/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras==3.3.3) (0.1.0)\n",
      "Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "Successfully installed keras-3.3.3\n"
     ]
    }
   ],
   "source": [
    "! pip install keras==3.3.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "3.3.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(tf.__version__)  # debe ser 2.17.0\n",
    "print(keras.__version__)  # debe ser 3.x.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/anaconda3/envs/arantxa/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import pkgutil\n",
    "print([m.module_finder.path for m in pkgutil.iter_modules() if \"keras\" in m.name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv1D, MaxPool1D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    restore_best_weights = True,\n",
    "    patience = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Con 36 años, como profesor, la cafetería cumple.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m y_test \u001b[38;5;241m=\u001b[39m to_categorical(y_test, \u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arantxa/lib/python3.10/site-packages/keras/utils/np_utils.py:62\u001b[0m, in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arantxa/lib/python3.10/site-packages/pandas/core/series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Con 36 años, como profesor, la cafetería cumple.'"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, 5)\n",
    "y_test = to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(30,2,activation = 'relu', input_shape = X_train[0].shape))\n",
    "model.add(MaxPool1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(35, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate = 0.01),\n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    callbacks = [early_stopping],\n",
    "                    epochs = 100, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(history.history)\n",
    "metrics.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(data = metrics[['loss', 'val_loss']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = metrics[['accuracy', 'val_accuracy']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis = -1)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis = -1)\n",
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred, target_names = target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot = True, fmt = '.0f')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arantxa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
